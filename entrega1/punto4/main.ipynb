{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67829275",
   "metadata": {},
   "source": [
    "Primer Job Formater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70b0e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRE import Job\n",
    "inputDir = \"./jugadores/\"\n",
    "promedioDir = \"../punto2/contabilizado/\"\n",
    "outputDir = \"./format/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb3c2769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def fmap(key, value, context):\n",
    "    lista = value.split()\n",
    "    j_retador = int(key)\n",
    "    j_retado = int(lista[0])\n",
    "    context.write((j_retado,'RETADO'), j_retador)\n",
    "def fmap2(key, value, context):\n",
    "    lista = value.split()\n",
    "    context.write((int(key), 'PP')  , ((float(lista[0]) + 1)/(float(lista[1])+1)))\n",
    "\n",
    "def cmpShort(key1,key2):\n",
    "    if(key1[0] == key2[0]):\n",
    "        return 0\n",
    "    elif(key1[0] < key2[0]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def cmpShuffle(key1, key2):\n",
    "    if(key1[1] == key2[1]):\n",
    "        return 0\n",
    "    elif(key1[1] == \"PP\"): #PP es el primero \n",
    "        return -1\n",
    "    else:\n",
    "        return 1 #Caso retado\n",
    "\n",
    "def fred(key, values, context):\n",
    "    # El primer valor DEBE ser el PP del jugador J por el cmpShuffle\n",
    "    pp_jugador_j = float(values.next())\n",
    "    \n",
    "    # Iteramos sobre los retadores (los 'v' son los ID de los jugadores J)\n",
    "    for id_retador in values:\n",
    "        # Enviamos al retador la información de su retado:\n",
    "        # (ID_Retador, (PH_del_retado, PP_del_retado))\n",
    "        context.write(id_retador, (puntaje_heroico_inicial, pp_jugador_j))\n",
    "\n",
    "    \n",
    "puntaje_heroico_inicial = 1\n",
    "\n",
    "jobCount = Job(inputDir, outputDir, fmap, fred)\n",
    "jobCount.setSortCmp(cmpShuffle)\n",
    "jobCount.setShuffleCmp(cmpShort)\n",
    "jobCount.setParams(puntaje_heroico_inicial)\n",
    "jobCount.addInputPath(promedioDir,fmap2)\n",
    "\n",
    "success = jobCount.waitForCompletion()\n",
    "\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875849c3",
   "metadata": {},
   "source": [
    "Segundo job iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "687b3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir = \"./format/\"\n",
    "outputDir = \"./format/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cffe0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Iteración 0 - MAE: 1257.551749\n",
      ">>> Iteración 1 - MAE: 1812.838400\n",
      ">>> Iteración 2 - MAE: 1812.838400\n",
      ">>> Iteración 3 - MAE: 1812.838400\n",
      ">>> Iteración 4 - MAE: 1812.838400\n",
      ">>> Iteración 5 - MAE: 1812.838400\n",
      ">>> Iteración 6 - MAE: 1812.838400\n",
      ">>> Iteración 7 - MAE: 1812.838400\n",
      ">>> Iteración 8 - MAE: 1812.838400\n",
      ">>> Iteración 9 - MAE: 1812.838400\n",
      ">>> Iteración 10 - MAE: 1812.838400\n",
      ">>> Iteración 11 - MAE: 1812.838400\n",
      ">>> Iteración 12 - MAE: 1812.838400\n",
      ">>> Iteración 13 - MAE: 1812.838400\n",
      ">>> Iteración 14 - MAE: 1812.838400\n",
      ">>> Iteración 15 - MAE: 1812.838400\n",
      ">>> Iteración 16 - MAE: 1812.838400\n",
      ">>> Iteración 17 - MAE: 1812.838400\n",
      ">>> Iteración 18 - MAE: 1812.838400\n",
      ">>> Iteración 19 - MAE: 1812.838400\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def fmap(key, value, context):\n",
    "    lista = value.split(\"\\t\")\n",
    "    context.write((key,\"ESTRUCTURA\"),lista)\n",
    "    set_limpio = lista[1].strip(\"{} \").split(\",\")\n",
    "    if set_limpio[0] != '':\n",
    "        for v in set_limpio:\n",
    "            v = v.strip()\n",
    "            context.write((v, \"CONTRIBUCION\"), (lista[0],lista[-1]))\n",
    "\n",
    "def cmpShort(key1,key2):\n",
    "    if(key1[0] == key2[0]):\n",
    "        return 0\n",
    "    elif(key1[0] < key2[0]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def cmpShuffle(key1, key2):\n",
    "    if(key1[1] == key2[1]):\n",
    "        return 0\n",
    "    elif(key1[1] == \"ESTRUCTURA\"): #PP y PH es el primero \n",
    "        return -1\n",
    "    else:\n",
    "        return 1 #Caso Contribucion\n",
    "\n",
    "def fred(key, values, context):\n",
    "    # 'values' es un ValuesIterator\n",
    "    estructura = next(values) \n",
    "    # Estructura esperada: [PP_i, {lista_de_retados}, PH_viejo]\n",
    "    \n",
    "    pp_i = float(estructura[0])\n",
    "    ph_viejo = float(estructura[-1])\n",
    "    retados = estructura[1]\n",
    "    \n",
    "    acumulador = 0\n",
    "    for v in values:\n",
    "        # v viene del Mapper como (PP_j, PH_j)\n",
    "        pp_j = float(v[0])\n",
    "        ph_j = float(v[1])\n",
    "        acumulador += ph_j * (pp_i / pp_j)\n",
    "    \n",
    "    nuevo_ph = (alfa * acumulador) + (1 - alfa)\n",
    "    \n",
    "    # Emitimos manteniendo la estructura para la siguiente iteración\n",
    "    # Formato: ID \\t PP \\t {Retados} \\t PH_Nuevo\n",
    "    context.write(key[0], [pp_i, retados, nuevo_ph, ph_viejo])\n",
    "\n",
    "\n",
    "\n",
    "# JOB INTERMEDIO QUE SOLO CALCULA EL MAE ENTRE DOS ITERACIONES\n",
    "def map_mae(key, value, context):\n",
    "    # Asumiendo que la estructura de value es: [PP, {Retados}, PH_Nuevo, PH_Viejo]\n",
    "    # Si 'value' viene de disco como string, hay que parsearlo\n",
    "    datos = value.split(\"\\t\")\n",
    "        \n",
    "    ph_nuevo = float(datos[2])\n",
    "    ph_viejo = float(datos[3])\n",
    "    \n",
    "    # Calculamos el error absoluto: |PH_nuevo - PH_viejo|\n",
    "    error_absoluto = abs(ph_nuevo - ph_viejo)\n",
    "    \n",
    "    # Enviamos a una clave fija para que un Reducer calcule el promedio final\n",
    "    # Emitimos (error, 1) para poder calcular el promedio (Suma / Total)\n",
    "    context.write(\"GLOBAL_MAE\", (error_absoluto, 1))\n",
    "\n",
    "def red_mae(key, values, context):\n",
    "    suma_error_absoluto = 0\n",
    "    conteo_jugadores = 0\n",
    "    \n",
    "    for err, count in values:\n",
    "        suma_error_absoluto += err\n",
    "        conteo_jugadores += count\n",
    "    \n",
    "    # MAE = Suma de errores absolutos / N\n",
    "    mae_final = suma_error_absoluto / conteo_jugadores if conteo_jugadores > 0 else 0\n",
    "    \n",
    "    context.write(\"RESULTADO_MAE\", mae_final)\n",
    "\n",
    "\n",
    "# Parámetros iniciales\n",
    "alfa = 0.1\n",
    "error_tolerado = 0.001\n",
    "max_iter = 20\n",
    "input_dir = \"./format/\" # Salida del Job anterior (ID \\t [PP, PH, {Retados}])\n",
    "\n",
    "for i in range(max_iter):\n",
    "    output_dir = f\"./iteracion_{i}/\"\n",
    "    \n",
    "    # Configuramos el Job\n",
    "    job = Job(input_dir, output_dir, fmap, fred)\n",
    "    job.setParams(alfa)\n",
    "    job.setShuffleCmp(cmpShort)\n",
    "    job.setSortCmp(cmpShuffle)\n",
    "    \n",
    "    success = job.waitForCompletion()\n",
    "    \n",
    "    # --- CÁLCULO DE CONVERGENCIA (MSE) ---\n",
    "    mae_dir = f\"./mae_iter_{i}/\"\n",
    "    \n",
    "    # 1. Ejecutar Job de cálculo de PH (el que ya tienes)\n",
    "    # 2. Ejecutar Job de MAE\n",
    "    jobMAE = Job(output_dir, mae_dir, map_mae, red_mae)\n",
    "    jobMAE.waitForCompletion()\n",
    "    \n",
    "    # 3. Leer el resultado del MAE desde el Driver\n",
    "    # (El driver solo lee un archivo de texto de pocos bytes)\n",
    "    try:\n",
    "        with open(f\"{mae_dir}/output.txt\", \"r\") as f:\n",
    "            # Formato esperado: RESULTADO_MAE \\t 0.00045\n",
    "            linea = f.read().split(\"\\t\")\n",
    "            mae_actual = float(linea[1])\n",
    "            \n",
    "        print(f\">>> Iteración {i} - MAE: {mae_actual:.6f}\")\n",
    "        \n",
    "        if mae_actual < error_tolerado:\n",
    "            print(f\"Convergió en iteración {i} con MAE {mae_actual}\")\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo MAE: {e}\")\n",
    "        break\n",
    "    \n",
    "    # El output de esta vuelta es el input de la siguiente\n",
    "    input_dir = output_dir\n",
    "\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e2373",
   "metadata": {},
   "source": [
    "Tercer Job saca top 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f74dc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir = \"./format/\"\n",
    "outputDir = \"./out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e4a520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    lista = value.split(\"\\t\")\n",
    "    context.write(1, (key, float(lista[-1])))\n",
    "\n",
    "def fcombiner(key, values, context):\n",
    "    # simple combiner: sum counts locally\n",
    "    top_maximo = []\n",
    "    \n",
    "    for v in values:\n",
    "        elemento = (v[1],v[0])\n",
    "        if len(top_maximo) < 10:\n",
    "            # Si hay menos de 10 elementos, simplemente lo añadimos al heap.\n",
    "            heapq.heappush(top_maximo, elemento)\n",
    "        else:\n",
    "            # Si el nuevo score (elemento[0]) es MAYOR que el elemento MÁS PEQUEÑO \n",
    "            # del heap (top_maximo[0]), reemplazamos el pequeño.\n",
    "            if elemento[0] > top_maximo[0][0]:\n",
    "                heapq.heapreplace(top_maximo, elemento)\n",
    "    top_10_final = sorted(top_maximo, key=lambda e: e[0], reverse=True)\n",
    "    for (maximo, clave) in top_10_final:\n",
    "        context.write(key, (clave,maximo))\n",
    "\n",
    "def fred(key, values, context):\n",
    "    # simple combiner: sum counts locally\n",
    "    top_maximo = []\n",
    "    \n",
    "    for v in values:\n",
    "        elemento = (v[1],v[0])\n",
    "        if len(top_maximo) < 10:\n",
    "            # Si hay menos de 10 elementos, simplemente lo añadimos al heap.\n",
    "            heapq.heappush(top_maximo, elemento)\n",
    "        else:\n",
    "            # Si el nuevo score (elemento[0]) es MAYOR que el elemento MÁS PEQUEÑO \n",
    "            # del heap (top_maximo[0]), reemplazamos el pequeño.\n",
    "            if elemento[0] > top_maximo[0][0]:\n",
    "                heapq.heapreplace(top_maximo, elemento)\n",
    "    top_10_final = sorted(top_maximo, key=lambda e: e[0], reverse=True)\n",
    "    for (maximo, clave) in top_10_final:\n",
    "        context.write(clave, maximo)\n",
    "\n",
    "jobCountBoth = Job(inputDir, outputDir, fmap, fred)\n",
    "jobCountBoth.setCombiner(fcombiner)\n",
    "success = jobCountBoth.waitForCompletion()\n",
    "\n",
    "print(success)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
